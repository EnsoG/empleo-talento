"""
GuÃ­a de uso del scraper de Codelco
"""

import asyncio
from scrapers.codelco_scraper import CodelcoScraper


async def demo_scraper():
    """DemostraciÃ³n del uso del scraper"""
    print("ğŸ¯ GUÃA DE USO DEL SCRAPER DE CODELCO")
    print("=" * 60)
    
    print("\nğŸ“‹ OPCIONES DISPONIBLES:")
    print("1. Ejecutar scraper completo")
    print("2. Solo prueba de conexiÃ³n")
    print("3. Ver empleos guardados")
    print("4. Salir")
    
    while True:
        try:
            opcion = input("\nğŸ‘‰ Selecciona una opciÃ³n (1-4): ").strip()
            
            if opcion == "1":
                print("\nğŸš€ Ejecutando scraper completo...")
                scraper = CodelcoScraper()
                
                # Ejecutar scraping completo
                jobs = await scraper.scrape_all_jobs()
                
                if jobs:
                    # Guardar resultados
                    filename = scraper.save_to_json(jobs)
                    
                    print(f"\nâœ… Â¡Scraping completado!")
                    print(f"ğŸ“Š Total de empleos: {len(jobs)}")
                    print(f"ğŸ“ Archivo guardado: {filename}")
                    
                    # Mostrar resumen por regiÃ³n
                    regiones = {}
                    for job in jobs:
                        region = job.region
                        if region in regiones:
                            regiones[region] += 1
                        else:
                            regiones[region] = 1
                    
                    print(f"\nğŸ“ EMPLEOS POR REGIÃ“N:")
                    for region, count in regiones.items():
                        print(f"   {region}: {count} empleos")
                else:
                    print("âŒ No se encontraron empleos")
                    
            elif opcion == "2":
                print("\nğŸ§ª Probando conexiÃ³n...")
                scraper = CodelcoScraper()
                
                import aiohttp
                async with aiohttp.ClientSession() as session:
                    html = await scraper.fetch_page(session, scraper.search_url)
                    
                    if html:
                        jobs = scraper.extract_job_links_and_basic_info(html)
                        print(f"âœ… ConexiÃ³n exitosa")
                        print(f"ğŸ“„ TamaÃ±o de pÃ¡gina: {len(html)} caracteres")
                        print(f"ğŸ“‹ Empleos encontrados: {len(jobs)}")
                        
                        if jobs:
                            print(f"\nğŸ”¸ Primer empleo encontrado:")
                            first_job = jobs[0]
                            print(f"   TÃ­tulo: {first_job['titulo']}")
                            print(f"   ID: {first_job['id_proceso']}")
                            print(f"   Fecha: {first_job['fecha']}")
                            print(f"   RegiÃ³n: {first_job['region']}")
                    else:
                        print("âŒ Error de conexiÃ³n")
                        
            elif opcion == "3":
                print("\nğŸ“ Buscando archivos de empleos guardados...")
                import os
                import glob
                
                # Buscar archivos JSON de empleos
                json_files = glob.glob("empleos_codelco_*.json")
                
                if json_files:
                    # Mostrar el archivo mÃ¡s reciente
                    latest_file = max(json_files, key=os.path.getctime)
                    print(f"ğŸ“‚ Archivo mÃ¡s reciente: {latest_file}")
                    
                    # Leer y mostrar resumen
                    import json
                    with open(latest_file, 'r', encoding='utf-8') as f:
                        jobs_data = json.load(f)
                    
                    print(f"ğŸ“Š Total de empleos en archivo: {len(jobs_data)}")
                    
                    if jobs_data:
                        print(f"\nğŸ“‹ ÃšLTIMOS 3 EMPLEOS:")
                        for i, job in enumerate(jobs_data[:3], 1):
                            print(f"\n{i}. {job['titulo']}")
                            print(f"   ID: {job['id_proceso']}")
                            print(f"   Fecha: {job['fecha']}")
                            print(f"   RegiÃ³n: {job['region']}")
                            print(f"   URL: {job['url']}")
                else:
                    print("ğŸ“‚ No se encontraron archivos de empleos guardados")
                    print("ğŸ’¡ Ejecuta la opciÃ³n 1 para crear un archivo de empleos")
                    
            elif opcion == "4":
                print("\nğŸ‘‹ Â¡Hasta luego!")
                break
                
            else:
                print("âŒ OpciÃ³n no vÃ¡lida. Selecciona 1, 2, 3 o 4.")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Â¡Hasta luego!")
            break
        except Exception as e:
            print(f"âŒ Error: {e}")


def show_usage_info():
    """Muestra informaciÃ³n de uso del scraper"""
    print("ğŸ“š INFORMACIÃ“N DEL SCRAPER DE CODELCO")
    print("=" * 50)
    
    print("\nğŸ¯ FUNCIONALIDADES:")
    print("â€¢ Extrae ofertas laborales de https://empleos.codelco.cl/search/")
    print("â€¢ Obtiene tÃ­tulo, fecha, regiÃ³n, cÃ³digo postal y detalles")
    print("â€¢ Guarda resultados en formato JSON")
    print("â€¢ Maneja duplicados automÃ¡ticamente")
    print("â€¢ Incluye informaciÃ³n adicional como horarios")
    
    print("\nğŸ”§ FORMAS DE USO:")
    print("1. Script interactivo: python src/scripts/demo_scraper.py")
    print("2. Scraper directo: python src/scripts/run_codelco_scraper.py")
    print("3. API endpoints: /v1/scrapers/codelco/*")
    print("4. IntegraciÃ³n BD: python src/scripts/scrape_and_save_codelco.py")
    
    print("\nğŸ“Š ENDPOINTS API DISPONIBLES:")
    print("â€¢ GET /v1/scrapers/codelco/test - Prueba el scraper")
    print("â€¢ POST /v1/scrapers/codelco/run - Ejecuta scraping completo")
    print("â€¢ GET /v1/scrapers/codelco/jobs - Lista empleos guardados")
    print("â€¢ GET /v1/scrapers/status - Estado de scrapers")
    
    print("\nğŸ’¾ ARCHIVOS GENERADOS:")
    print("â€¢ empleos_codelco_YYYYMMDD_HHMMSS.json - Datos completos")
    print("â€¢ debug_codelco.html - HTML de la pÃ¡gina (para debugging)")
    
    print("\nâš™ï¸  CONFIGURACIÃ“N:")
    print("â€¢ User-Agent configurado para evitar bloqueos")
    print("â€¢ Pausas entre requests para no sobrecargar el servidor")
    print("â€¢ Manejo de errores y reintentos")
    print("â€¢ ExtracciÃ³n robusta usando selectores CSS especÃ­ficos")


if __name__ == "__main__":
    print("ğŸ¤– SCRAPER DE EMPLEOS DE CODELCO")
    print("=" * 40)
    
    print("\nÂ¿QuÃ© quieres hacer?")
    print("1. Ver informaciÃ³n del scraper")
    print("2. Usar el scraper (modo interactivo)")
    
    try:
        choice = input("\nSelecciona 1 o 2: ").strip()
        
        if choice == "1":
            show_usage_info()
        elif choice == "2":
            asyncio.run(demo_scraper())
        else:
            print("âŒ OpciÃ³n no vÃ¡lida")
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Â¡Hasta luego!")
    except Exception as e:
        print(f"âŒ Error: {e}")
